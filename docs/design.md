These are the primary design constraints:

* We may receive logging events on any thread, and don't want to block the thread while communicating
  with the service.
* Services may reject our requests, either temporarily or permanently.
* We generally want to batch individual messages to improve throughput, respecting any limits on
  number of messages or bytes that are imposed by the service.
* The amount of time taken to build a batch should be controllable by the user, as a trade-off
  between efficiency and potential for lost messages.

To meet these constraints, the appender creates a separate thread for communication with the service,
with a concurrent queue to hold appended messages. When Log4J calls `append()`, the appender converts
the passed `LoggingEvent` into a  textual representation, verifies that it conforms to limitations
imposed by the service, and adds it to the queue.

The writer consumes that queue, attempting to batch together messages into a single request. Once it
has a batch (either based on size or a configurable timeout) it attempts to write those messages to
the service. In addition to retries embedded within the AWS SDK, the writer will requeue messages
that can't be sent, dropping messages once a user-configurable threshold is reached.

The writer thread is lazily started on the first call to `append()`. There's a factory for writer
objects and writer threads, to support testing. If unable to start the writer thread, all messages
are dropped and the situation is reported to the internal logger.

The writer thread handles most exceptions internally. Unexpected exceptions are reported using an
uncaught exception handler in the appender. This is considered an unrecoverable error, so the
appender discards its writer, clears the message queue, and drops all subsequent messages. The
error is reported to the internal logger and is also available from [JMX](jmx.md).


## Message Batches

Most AWS services allow batching of messages for efficiency. While sending maximum-sized requests is
more efficient when there's a high volume of logging, it would cause an excessive delay if there's a
low volume. And it will leave more messages unwritten if the program shuts down without waiting for
all messages to be sent.

The user can control message batching via the `batchDelay` configuration variable. All messages go on
an internal queue, and the writer thread blocks on this queue until a message is available. Once the
writer pulls a message off the queue, it starts a countdown timer with the specified delay, and waits
for additional messages until it either fills the batch (based on AWS limits) or the timer is at zero.
At that point it sends the batch and waits for another initial message.

The default value, 2000, is intended as a tradeoff between keeping the log up to date and minimizing
the number of API calls generated by the logger (to avoid throttling). For long-running applications
this default should be fine, but for applications that only run for a few seconds it may cause message
loss (the appenders do not attach a shutdown hook, and the JVM does not necessarily respect those anyway).
For such applications it makes sense to reduce the batch size to maybe 250 milliseconds, but beware that
increasing the message rate may result in AWS throttling requests, which could extend the actual delay
between a logging event and that event being written to its destination.

If you absolutely, positively cannot lose messages, you should use a different appender. But beware:
even the standard `FileAppender` is not guaranteed to save all messages, because file writes are
buffered in memory before they're actually written to the disk.


## Message Discard

The appenders will attempt to deliver every message, requeing messages that can't be sent (this is
particuarly relevant to the Kinesis appender, since some messages in a batch may fail while others
succeed). If there are persistent errors, such as a network outage, an unconstrained queue could
consume all of the program's memory.

To avoid such errors, the queue has a maximum size, configured by the `discardThreshold` parameter.
How it behaves once the queue is full is configured by the `discardAction` parameter:

* `oldest` - the oldest message in the queue is discarded; this is the default, as it allows you to
  track the current behavior of the application once the failure condition is resolved.
* `newest` - the newest message in the queue is discarded. This is useful if you want to see what
  was happening at the time the failure condition occured.
* `none` - no messages are discarded. If you expect intermittent connectivity problems, have lots of
  memory, and don't want to miss any logging then this option may be reasonable. However, it's probably
  better to increase the threshold and use one of the other discard actions.

The default threshold is 10,000 messages. Assuming 1kb per message, that's 10MB of heap that will be
used by the queue. 

## Service Client

In order to support all AWS releases in the 1.11.x sequence, the appenders must support
the default client constructors. However, these constructors have a few limitations:

* While they use a [credentials provider chain](https://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/com/amazonaws/auth/DefaultAWSCredentialsProviderChain.html)
  that looks for client credentials in multiple locations, they don't do the same for region.
  Instead, they default to the `us-east-1` region and expect applications to change the client
  after construction. However, the appenders don't expose their client, so there's no way to
  do this.
* Some use cases require providing credentials other than those that the will be picked up by
  the default provider chain. For example, you might direct logging to a stream or topic owned
  by a different AWS account.

To work-around these limitations, the appenders will look first for the default client factory,
and invoke it using reflection. The default client factory, in addition to retrieving credentials
from a provider chain, also retrieves the region from a similar chain. If you just want to ensure
that your logging destination is in the same region where you're running, you'll get this by using
a recent AWS SDK.

If you want more control -- for example, to write to destinations in a different region from
where you're running -- there are several configuration parameters that can help you. These
are applied in the order listed:

* You can specify a static factory method to create the client, using the `clientFactory`
  configuration parameter. This is specified as a fully-qualified classname, followed by
  a dot and the method name. For example, to use the default CloudWatch Logs factory (this
  is shown for example only, as the appender will use this method if available):

  ```
  log4j.appender.cloudwatch.clientFactory=com.amazonaws.services.logs.AWSLogsClientBuilder.defaultClient
  ```
* You can specify the client endpoint using the `clientEndpoint` configuration parameter;
  see the [AWS docs](https://docs.aws.amazon.com/general/latest/gr/rande.html) for a list
  of endpoint names. This parameter is primarily intended for applications that must use
  an older AWS SDK version but want to log outside the `us-east-1` region. For example, to
  direct Kinesis logging to a stream in the `us-west-1` region:

  ```
  log4j.appender.kinesis.clientEndpoint=kinesis.us-west-1.amazonaws.com
  ```

If you absolutely must use an older SDK, and neither of these options work for you, you can
specify the `AWS_REGION` environment variable. However, be aware that older SDKs do not
recognize all regions, so this is not a terribly good work-around.
